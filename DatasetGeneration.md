# Dataset Generation

You can use the notebooks in the folder [computer-vision-notebooks](./computer-vision-notebooks/) to label images and generate a dataset.

To do that you need to clear the [./computer-vision-notebooks/datasets] sub folders. You need to make sure the the folders `./computer-vision-notebooks/datasets/classify`, `./computer-vision-notebooks/datasets/classify/train`, `./computer-vision-notebooks/datasets/classify/val`, `./computer-vision-notebooks/datasets/detect/train/images`, `./computer-vision-notebooks/datasets/detect`, `./computer-vision-notebooks/datasets/detect/train/labels`, `./computer-vision-notebooks/datasets/detect/val/images` and `./computer-vision-notebooks/datasets/detect/val/labels` contains only the file `.gitkeep` and no `.cache` files.

Next, you need to copy all of your datasets images to `./computer-vision-notebooks/datasets/detect/train/images` and `./computer-vision-notebooks/datasets/detect/val/images`.

Such image files for the dataset can be automatically generated by the simulated wolrd in [./webots/object_recognition_project/worlds/dataset_generation.wbt](./webots/object_recognition_project/worlds/dataset_generation.wbt). After loading the world, set the `controllerArgs` property of `Robot "camera"` to the `DEF` of the object, e.g. `"Plate1"`. Then, you can start the simulation and wait for the controller to end its job. This should be repeated for all of the objects. You can set the required number of training and validation images in the python controller [./webots/object_recognition_project/controllers/dataset_generator_controller/dataset_generator_controller.py](./webots/object_recognition_project/controllers/dataset_generator_controller/dataset_generator_controller.py). After all objects are captured you will find all image files in the folder [./webots/object_recognition_project/controllers/dataset_generator_controller/output/](./webots/object_recognition_project/controllers/dataset_generator_controller/output/). Copy all of the images to `./computer-vision-notebooks/datasets/detect`.

Alternatively, you can take real images and put them in the folder.

Next, you need to execute the automated labeling of the two datasets.

Now, open the Notebook [./computer-vision-notebooks/label-detect.ipynb](./computer-vision-notebooks/label-detect.ipynb), tweak the parameters and execute it.

Next, open the Notebook [./computer-vision-notebooks/label-classify.ipynb](./computer-vision-notebooks/label-classify.ipynb), tweak the parameters and execute it.

Now, the two datasets are complete.

Next, you need to train the models. This can be done as shown in the Notebook [./computer-vision-notebooks/train-yolov8.ipynb](./computer-vision-notebooks/train-yolov8.ipynb). You only need to train the detect and the classify models. The obb model is not used.

After the models are trained, you can use them as described in [./computer-vision-notebooks/amropick-demo.ipynb](./computer-vision-notebooks/amropick-demo.ipynb).
