{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82a925ba-e495-4d5c-8007-8061ba24e601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 4, 28.4ms\n",
      "Speed: 15.0ms preprocess, 28.4ms inference, 4.6ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 4, 20.2ms\n",
      "Speed: 14.3ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 3 Plate 2s, 11.1ms\n",
      "Speed: 13.1ms preprocess, 11.1ms inference, 3.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 3 Plate 2s, 13.4ms\n",
      "Speed: 13.2ms preprocess, 13.4ms inference, 18.8ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 2 Plate 2s, 1 Plate 3, 17.3ms\n",
      "Speed: 14.6ms preprocess, 17.3ms inference, 19.0ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 2 Plate 2s, 1 Plate 3, 13.2ms\n",
      "Speed: 15.5ms preprocess, 13.2ms inference, 3.1ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 3, 11.4ms\n",
      "Speed: 13.4ms preprocess, 11.4ms inference, 4.7ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 3, 11.3ms\n",
      "Speed: 15.2ms preprocess, 11.3ms inference, 2.8ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 3 Plate 2s, 15.2ms\n",
      "Speed: 14.2ms preprocess, 15.2ms inference, 3.0ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 3 Plate 2s, 17.8ms\n",
      "Speed: 13.3ms preprocess, 17.8ms inference, 18.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 2 Plate 2s, 1 Plate 5, 18.3ms\n",
      "Speed: 14.1ms preprocess, 18.3ms inference, 18.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 2 Plate 2s, 1 Plate 5, 13.3ms\n",
      "Speed: 16.9ms preprocess, 13.3ms inference, 2.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 1, 1 Plate 2, 1 Plate 5, 12.9ms\n",
      "Speed: 14.0ms preprocess, 12.9ms inference, 18.8ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 1, 1 Plate 2, 1 Plate 5, 21.7ms\n",
      "Speed: 14.0ms preprocess, 21.7ms inference, 18.7ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 5, 21.6ms\n",
      "Speed: 13.7ms preprocess, 21.6ms inference, 11.5ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 5, 17.9ms\n",
      "Speed: 16.2ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 1, 1 Plate 2, 21.7ms\n",
      "Speed: 15.6ms preprocess, 21.7ms inference, 7.2ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 1, 1 Plate 2, 11.2ms\n",
      "Speed: 16.9ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 (no detections), 15.8ms\n",
      "Speed: 13.8ms preprocess, 15.8ms inference, 6.8ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 (no detections), 18.3ms\n",
      "Speed: 14.2ms preprocess, 18.3ms inference, 7.0ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 4, 21.7ms\n",
      "Speed: 14.8ms preprocess, 21.7ms inference, 5.0ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 4, 15.5ms\n",
      "Speed: 17.4ms preprocess, 15.5ms inference, 2.8ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 (no detections), 21.4ms\n",
      "Speed: 16.0ms preprocess, 21.4ms inference, 6.8ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 (no detections), 17.8ms\n",
      "Speed: 13.6ms preprocess, 17.8ms inference, 6.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 17.6ms\n",
      "Speed: 15.8ms preprocess, 17.6ms inference, 3.0ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 13.3ms\n",
      "Speed: 16.9ms preprocess, 13.3ms inference, 3.0ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 4, 11.2ms\n",
      "Speed: 13.4ms preprocess, 11.2ms inference, 3.4ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 4, 11.2ms\n",
      "Speed: 14.1ms preprocess, 11.2ms inference, 3.0ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 4, 21.6ms\n",
      "Speed: 16.9ms preprocess, 21.6ms inference, 18.6ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 4, 21.5ms\n",
      "Speed: 15.4ms preprocess, 21.5ms inference, 4.4ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 3, 21.7ms\n",
      "Speed: 14.9ms preprocess, 21.7ms inference, 11.5ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 3, 15.5ms\n",
      "Speed: 16.7ms preprocess, 15.5ms inference, 2.2ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 3, 19.5ms\n",
      "Speed: 13.8ms preprocess, 19.5ms inference, 18.7ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 3, 21.6ms\n",
      "Speed: 14.0ms preprocess, 21.6ms inference, 18.5ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 4, 21.7ms\n",
      "Speed: 14.1ms preprocess, 21.7ms inference, 11.6ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 4, 15.6ms\n",
      "Speed: 14.4ms preprocess, 15.6ms inference, 2.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 3, 15.9ms\n",
      "Speed: 15.0ms preprocess, 15.9ms inference, 18.7ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 3, 21.7ms\n",
      "Speed: 15.0ms preprocess, 21.7ms inference, 18.6ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 5, 21.7ms\n",
      "Speed: 15.3ms preprocess, 21.7ms inference, 12.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 5, 15.4ms\n",
      "Speed: 16.2ms preprocess, 15.4ms inference, 2.3ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 1, 15.6ms\n",
      "Speed: 14.6ms preprocess, 15.6ms inference, 18.6ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 1, 21.7ms\n",
      "Speed: 14.6ms preprocess, 21.7ms inference, 18.7ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 1, 17.7ms\n",
      "Speed: 14.9ms preprocess, 17.7ms inference, 18.7ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 1, 15.4ms\n",
      "Speed: 16.1ms preprocess, 15.4ms inference, 2.4ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 5, 21.5ms\n",
      "Speed: 15.9ms preprocess, 21.5ms inference, 9.5ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 5, 15.5ms\n",
      "Speed: 16.9ms preprocess, 15.5ms inference, 2.4ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 3, 11.2ms\n",
      "Speed: 13.5ms preprocess, 11.2ms inference, 4.2ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 3, 11.2ms\n",
      "Speed: 12.7ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 4, 1 Plate 5, 16.3ms\n",
      "Speed: 14.8ms preprocess, 16.3ms inference, 18.8ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 2, 1 Plate 4, 1 Plate 5, 21.6ms\n",
      "Speed: 13.5ms preprocess, 21.6ms inference, 13.2ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 4, 1 Plate 5, 21.6ms\n",
      "Speed: 16.5ms preprocess, 21.6ms inference, 15.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 4, 1 Plate 5, 21.6ms\n",
      "Speed: 15.9ms preprocess, 21.6ms inference, 16.2ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 2 Plate 5s, 11.5ms\n",
      "Speed: 12.7ms preprocess, 11.5ms inference, 2.7ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 2 Plate 5s, 10.0ms\n",
      "Speed: 12.3ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 2 Plate 5s, 17.5ms\n",
      "Speed: 13.6ms preprocess, 17.5ms inference, 2.4ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 2 Plate 5s, 11.0ms\n",
      "Speed: 16.8ms preprocess, 11.0ms inference, 2.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 5, 11.1ms\n",
      "Speed: 13.6ms preprocess, 11.1ms inference, 2.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 1 Plate 5, 11.3ms\n",
      "Speed: 14.5ms preprocess, 11.3ms inference, 2.8ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 (no detections), 13.3ms\n",
      "Speed: 15.1ms preprocess, 13.3ms inference, 6.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 (no detections), 20.5ms\n",
      "Speed: 14.4ms preprocess, 20.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 (no detections), 21.7ms\n",
      "Speed: 14.0ms preprocess, 21.7ms inference, 6.9ms postprocess per image at shape (1, 3, 1440, 1920)\n",
      "\n",
      "0: 1440x1920 (no detections), 21.6ms\n",
      "Speed: 14.9ms preprocess, 21.6ms inference, 6.9ms postprocess per image at shape (1, 3, 1440, 1920)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "\n",
    "# dataset-4 -> v7 2025-06-04 2:05pm\n",
    "# dataset-5 -> v8 2025-06-04 6:40pm\n",
    "# dataset-6 -> v9 2025-06-04 7:16pm\n",
    "\n",
    "# train11 -> yolo train data=./dataset/data.yaml batch=0.8 model=yolo11n-seg.pt imgsz=1280 device=0 epochs=1000 patience=250\n",
    "# train13 -> yolo train data=./dataset/data.yaml batch=0.8 model=yolo11n-seg.pt imgsz=1920 device=0 epochs=2000 patience=300\n",
    "# train14 -> yolo train data=./dataset-new/data.yaml batch=0.8 model=yolo11n-seg.pt imgsz=1920 device=0 epochs=2000 patience=300\n",
    "# train17 -> yolo train data=./dataset-4/data.yaml batch=0.8 model=yolo11n-seg.pt device=0 epochs=2000 patience=300\n",
    "# train18 -> yolo train data=./dataset-5/data.yaml batch=0.8 model=yolo11n-seg.pt device=0 epochs=2000 patience=300\n",
    "# train20 -> yolo train data=./dataset-6/data.yaml batch=0.8 model=yolo11n-seg.pt device=0 epochs=2000 patience=300\n",
    "# train21 -> yolo train data=./dataset-5/data.yaml batch=0.8 model=yolo11n-seg.pt imgsz=1920 device=0 epochs=2000 patience=300\n",
    "# train22 -> yolo train data=./dataset-6/data.yaml batch=0.8 model=yolo11n-seg.pt imgsz=1920 device=0 epochs=2000 patience=300\n",
    "# train23 -> yolo train data=./dataset-6/data.yaml mosaic=0.0 batch=0.8 model=yolo11n-seg.pt device=0 epochs=1000\n",
    "# train24 -> yolo train data=./dataset-6/data.yaml mosaic=0.0 imgsz=1920 batch=0.8 model=yolo11n-seg.pt device=0 epochs=250\n",
    "\n",
    "# 5.mp4  -> video/video_1.mp4             -> train17 \n",
    "# 6.mp4  -> video/video_1.mp4             -> train18\n",
    "# 7.mp4  -> video/video_1.mp4             -> train20\n",
    "# 8.mp4  -> video/VID_20250603_193149.mp4 -> train17\n",
    "# 9.mp4  -> video/VID_20250603_193149.mp4 -> train18\n",
    "# 10.mp4 -> video/VID_20250603_193149.mp4 -> train20\n",
    "# 11.mp4 -> video/video_1.mp4             -> train21\n",
    "# 12.mp4 -> video/VID_20250603_193149.mp4 -> train21\n",
    "# 13.mp4 -> video/video_1.mp4             -> train22\n",
    "# 14.mp4 -> video/VID_20250603_193149.mp4 -> train22\n",
    "# 15.mp4 -> video/video_1.mp4             -> train23\n",
    "# 16.mp4 -> video/VID_20250603_193149.mp4 -> train23\n",
    "# 17.mp4 -> video/video_1.mp4             -> train24\n",
    "# 18.mp4 -> video/VID_20250603_193149.mp4 -> train24\n",
    "\n",
    "# === Параметри ===\n",
    "model = YOLO(\"../runs/segment/train24/weights/best.pt\")\n",
    "input_path = \"video/video_1.mp4\"\n",
    "# input_path = \"video/VID_20250603_193149.mp4\"\n",
    "output_path = \"demos/17.mp4\"\n",
    "process_fps = 1\n",
    "\n",
    "\n",
    "def get_precise_box(mask):\n",
    "    contours, _ = cv2.findContours(\n",
    "        mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        print(\"Object not found\")\n",
    "        return None, None\n",
    "\n",
    "    main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    M = cv2.moments(main_contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        center_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        center_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        center_x, center_y = 0, 0\n",
    "\n",
    "    rect = cv2.minAreaRect(main_contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int32(box)\n",
    "    angle = rect[2]\n",
    "\n",
    "    width, height = rect[1]\n",
    "    if width < height:\n",
    "        angle = 90 + angle\n",
    "    angle = 90 - angle\n",
    "\n",
    "    return main_contour, (center_x, center_y, angle, max(width, height), min(width, height))\n",
    "\n",
    "def process_image(image, model):\n",
    "    # model = YOLO(\"../runs/segment/train11/weights/best.pt\")\n",
    "    # # train11 is trained with yolo train data=./dataset/data.yaml batch=0.8 model=yolo11n-seg.pt imgsz=1280 device=0 epochs=1000 patience=250\n",
    "\n",
    "    result = model(image, conf=0.4)[0]\n",
    "\n",
    "    classes = result.boxes.cls.cpu().numpy()\n",
    "\n",
    "    confidences = result.boxes.conf.cpu().numpy()\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread(image)\n",
    "    except:\n",
    "        img = image.copy()\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    detected_objects = []\n",
    "    best_objects = {}\n",
    "    \n",
    "    # colors = np.random.randint(0, 255, size=(5,3), dtype=np.uint8)\n",
    "    \n",
    "    colors = [(255, 0, 0),\n",
    "              (0, 0, 255),\n",
    "              (0, 255, 255),\n",
    "              (255, 0, 255),\n",
    "              (255, 255, 0),\n",
    "              (255, 255, 255),\n",
    "              (0, 0, 0)]\n",
    "\n",
    "    try:\n",
    "        masks = result.masks.data.cpu().numpy()\n",
    "        img = cv2.resize(img, (masks.shape[2], masks.shape[1]))\n",
    "    except:\n",
    "        masks = []\n",
    "\n",
    "    for i, mask in enumerate(masks):\n",
    "        # color = tuple(int(c) for c in colors[int(classes[i])])\n",
    "        color = colors[int(classes[i])]\n",
    "        precise_box, (x, y, theta, w1, h1) = get_precise_box(mask.astype(np.uint8))\n",
    "    \n",
    "        x1, y1, w, h = cv2.boundingRect(precise_box)\n",
    "    \n",
    "        cv2.rectangle(img, (x1, y1), (x1 + w, y1 + h), (0, 0, 0), 1)\n",
    "        \n",
    "        cv2.circle(img, (x, y), 9, (0, 255, 0), -1)\n",
    "        start = (x, y)\n",
    "        end = (int(start[0] - math.sin(math.radians(theta)) * 70),\n",
    "               int(start[1] - math.cos(math.radians(theta)) * 70))\n",
    "        cv2.line(img, start, end, (0, 255, 0), 3)\n",
    "    \n",
    "        cv2.drawContours(img, [precise_box], -1, tuple(int(c) for c in color), 3)\n",
    "    \n",
    "        try:\n",
    "            predicted_class_name = f\"{model.names[int(classes[i])]}\"\n",
    "        except:\n",
    "            predicted_class_name = \"Unknown\"\n",
    "        \n",
    "        cv2.putText(img, predicted_class_name, (x1, y1 + h + 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)\n",
    "    \n",
    "        area = int(cv2.contourArea(precise_box))\n",
    "\n",
    "        z = int((w1 - (140 if classes[i] == 1 else 835)) / 5)\n",
    "        \n",
    "        cv2.putText(img, f\"{z:d} mm\", (x1, y1 + h + 100),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)\n",
    "        \n",
    "        # For the simulation in vision_pick_and_place.wbt:\n",
    "        #   x -> [0; 1280] =  [-0.4; 0.4]\n",
    "        #   y -> [0; 960] = -[-0.3; 0.3]\n",
    "        detected_object = {\n",
    "            \"name\": model.names[int(classes[i])],\n",
    "            \"confidence\": confidences[i],\n",
    "            \"area\": area,\n",
    "            \"x\": 0.8 * (x - (1280 + 0) / 2) / (120 - 0),\n",
    "            \"y\": - 0.6 * (y - (960 + 0) / 2) / (960 - 0),\n",
    "            \"z\": z,\n",
    "            \"theta\": math.radians(theta)\n",
    "        }\n",
    "    \n",
    "        detected_objects.append(detected_object)\n",
    "        if detected_object[\"name\"] not in best_objects or \\\n",
    "                best_objects[detected_object[\"name\"]][\"confidence\"] < detected_object[\"confidence\"]:\n",
    "            best_objects[detected_object[\"name\"]] = detected_object\n",
    "\n",
    "    return img, detected_objects, best_objects\n",
    "\n",
    "def resize_keep_aspect(image, target_height):\n",
    "    image = image.copy()\n",
    "    h, w = image.shape[:2]\n",
    "    scale = target_height / h\n",
    "    new_w = int(w * scale)\n",
    "    resized = cv2.resize(image, (new_w, target_height))\n",
    "    return resized\n",
    "\n",
    "\n",
    "\n",
    "# === Отваряне на видеото ===\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = 1920 # int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = 1080 # int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# === Видео записвач ===\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "processed_frame = np.zeros((height, width, 3), dtype=np.uint8)  # празен за начало\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Обработка на 1 кадър в секунда\n",
    "    if int(frame_count % round(fps)) == 0:\n",
    "\n",
    "        result = model(frame.copy(), conf=0.4)[0]\n",
    "        processed_frame = result.plot()\n",
    "\n",
    "        \n",
    "        processed_frame_2, detected_objects, _ = process_image(frame.copy(), model)\n",
    "\n",
    "    \n",
    "\n",
    "    # Показване в реално време\n",
    "    # plt.figure()\n",
    "    # plt.imshow(resize_keep_aspect(frame, 540))\n",
    "    # plt.show()\n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.imshow(resize_keep_aspect(processed_frame, 540))\n",
    "    # plt.show()\n",
    "\n",
    "    # print(frame.shape)\n",
    "    # print(processed_frame.shape)\n",
    "    \n",
    "    # Съединяване на оригинал и последния обработен\n",
    "    combined = np.zeros((1080, 1920, 3), np.uint8)\n",
    "    resized = resize_keep_aspect(frame, 540)\n",
    "    combined[270:810, :resized.shape[1]] = resized\n",
    "    resized = resize_keep_aspect(processed_frame, 540)\n",
    "    combined[:540, 960:960+resized.shape[1]] = resized\n",
    "    resized = resize_keep_aspect(processed_frame_2, 540)\n",
    "    combined[540:, 960:960+resized.shape[1]] = resized\n",
    "\n",
    "    # combined = np.zeros((1080, 1920, 3), np.uint8)\n",
    "    # resized = resize_keep_aspect(frame, 740)\n",
    "    # combined[170:910, :resized.shape[1]] = resized\n",
    "    # resized = resize_keep_aspect(processed_frame, 740)\n",
    "    # combined[170:910, 680:680+resized.shape[1]] = resized\n",
    "    # resized = resize_keep_aspect(processed_frame_2, 740)\n",
    "    # combined[170:910, 1360:1360+resized.shape[1]] = resized\n",
    "\n",
    "    # print(combined.shape)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(combined)\n",
    "    # plt.show()\n",
    "    \n",
    "    # Запис\n",
    "    out.write(combined)\n",
    "\n",
    "    # Прекъсване с ESC\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# === Освобождаване ===\n",
    "cap.release()\n",
    "out.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a613a-45df-4907-9e17-4f11acbd1649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb30df0-1c56-4faa-b3d0-5a0440beafd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
